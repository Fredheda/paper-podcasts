{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Paper Summarization\n",
    "\n",
    "This notebook demonstrates how to use the `LLMService` to generate audio-friendly summaries of research papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from src.services import LLMService, AnthropicProvider\n",
    "from src.models import Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Downloaded Paper\n",
    "\n",
    "First, let's load a paper from the downloads folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find metadata files in downloads folder\n",
    "download_dir = Path(\"downloads\")\n",
    "metadata_files = list(download_dir.glob(\"*.json\"))\n",
    "\n",
    "if not metadata_files:\n",
    "    print(\"No metadata files found in downloads folder!\")\n",
    "    print(\"Please download a paper first using the arxiv_example.ipynb notebook\")\n",
    "else:\n",
    "    # Load the first paper's metadata\n",
    "    metadata_path = metadata_files[0]\n",
    "    \n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    paper = Paper.from_dict(metadata)\n",
    "    \n",
    "    print(f\"Found {len(metadata_files)} paper(s) in downloads folder\")\n",
    "    print(f\"\\nPaper: {paper.title}\")\n",
    "    print(f\"Authors: {', '.join([a.name for a in paper.authors])}\")\n",
    "    print(f\"Published: {paper.published.strftime('%B %Y')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Extracted Content\n",
    "\n",
    "Check if we have already extracted the PDF content for this paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metadata_files:\n",
    "    # Find corresponding extracted content file\n",
    "    extracted_dir = Path(\"extracted_content\")\n",
    "    base_filename = paper.pdf_filename.replace(\".pdf\", \"\")\n",
    "    extracted_path = extracted_dir / f\"{base_filename}.md\"\n",
    "    \n",
    "    if not extracted_path.exists():\n",
    "        print(f\"Extracted content not found at: {extracted_path}\")\n",
    "        print(\"Please extract the PDF content first using the pdf_extraction_example.ipynb notebook\")\n",
    "    else:\n",
    "        print(f\"Found extracted content at: {extracted_path}\")\n",
    "        \n",
    "        # Show size of extracted content\n",
    "        with open(extracted_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        print(f\"Content length: {len(content):,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM Service\n",
    "\n",
    "The service requires an `ANTHROPIC_API_KEY` environment variable to be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use default settings (Anthropic provider, reads API key from env)\n",
    "anthropic_api_key = os.getenv(\"anthropic_api_key\")\n",
    "provider = AnthropicProvider(model=\"claude-haiku-4-5\", api_key=anthropic_api_key)\n",
    "llm_service = LLMService(provider=provider)\n",
    "\n",
    "\n",
    "print(\"LLM Service initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Summary\n",
    "\n",
    "Now let's generate an audio-friendly summary of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metadata_files and extracted_path.exists():\n",
    "    print(\"Generating summary...\\n\")\n",
    "    \n",
    "    summary = llm_service.summarize_paper_from_files(\n",
    "        paper=paper,\n",
    "        extracted_content_path=str(extracted_path),\n",
    "        prompt_name=\"summarize_paper\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=4096,\n",
    "        output_dir=\"summaries\"\n",
    "    )\n",
    "    \n",
    "    print(\"GENERATED SUMMARY\")\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-podcasts-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
